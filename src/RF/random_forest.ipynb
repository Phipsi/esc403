{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Standort</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>VELO_IN</th>\n",
       "      <th>VELO_OUT</th>\n",
       "      <th>FUSS_IN</th>\n",
       "      <th>FUSS_OUT</th>\n",
       "      <th>Ost</th>\n",
       "      <th>Nord</th>\n",
       "      <th>...</th>\n",
       "      <th>p [hPa]</th>\n",
       "      <th>Year</th>\n",
       "      <th>AnzBestWir</th>\n",
       "      <th>bezeichnung</th>\n",
       "      <th>fk_zaehler</th>\n",
       "      <th>id1</th>\n",
       "      <th>richtung_in</th>\n",
       "      <th>richtung_out</th>\n",
       "      <th>korrekturfaktor</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2023-01-01 00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2682689</td>\n",
       "      <td>1247735</td>\n",
       "      <td>...</td>\n",
       "      <td>971.62</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>447082.0</td>\n",
       "      <td>Militärbrücke</td>\n",
       "      <td>U15G3063864</td>\n",
       "      <td>20</td>\n",
       "      <td>Löwenplatz</td>\n",
       "      <td>Langstrasse</td>\n",
       "      <td>0.58</td>\n",
       "      <td>POINT (2682689 1247734.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>01:00</td>\n",
       "      <td>2023-01-01 01:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2682689</td>\n",
       "      <td>1247735</td>\n",
       "      <td>...</td>\n",
       "      <td>971.86</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>447082.0</td>\n",
       "      <td>Militärbrücke</td>\n",
       "      <td>U15G3063864</td>\n",
       "      <td>20</td>\n",
       "      <td>Löwenplatz</td>\n",
       "      <td>Langstrasse</td>\n",
       "      <td>0.58</td>\n",
       "      <td>POINT (2682689 1247734.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>02:00</td>\n",
       "      <td>2023-01-01 02:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2682689</td>\n",
       "      <td>1247735</td>\n",
       "      <td>...</td>\n",
       "      <td>971.76</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>447082.0</td>\n",
       "      <td>Militärbrücke</td>\n",
       "      <td>U15G3063864</td>\n",
       "      <td>20</td>\n",
       "      <td>Löwenplatz</td>\n",
       "      <td>Langstrasse</td>\n",
       "      <td>0.58</td>\n",
       "      <td>POINT (2682689 1247734.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>03:00</td>\n",
       "      <td>2023-01-01 03:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2682689</td>\n",
       "      <td>1247735</td>\n",
       "      <td>...</td>\n",
       "      <td>972.01</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>447082.0</td>\n",
       "      <td>Militärbrücke</td>\n",
       "      <td>U15G3063864</td>\n",
       "      <td>20</td>\n",
       "      <td>Löwenplatz</td>\n",
       "      <td>Langstrasse</td>\n",
       "      <td>0.58</td>\n",
       "      <td>POINT (2682689 1247734.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>04:00</td>\n",
       "      <td>2023-01-01 04:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2682689</td>\n",
       "      <td>1247735</td>\n",
       "      <td>...</td>\n",
       "      <td>972.10</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>447082.0</td>\n",
       "      <td>Militärbrücke</td>\n",
       "      <td>U15G3063864</td>\n",
       "      <td>20</td>\n",
       "      <td>Löwenplatz</td>\n",
       "      <td>Langstrasse</td>\n",
       "      <td>0.58</td>\n",
       "      <td>POINT (2682689 1247734.9)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Standort        Date   Time          Datetime  VELO_IN  VELO_OUT  FUSS_IN  \\\n",
       "0        20  2023-01-01  00:00  2023-01-01 00:00      0.0       0.0     46.0   \n",
       "1        20  2023-01-01  01:00  2023-01-01 01:00      0.0       0.0     43.0   \n",
       "2        20  2023-01-01  02:00  2023-01-01 02:00      0.0       0.0     36.0   \n",
       "3        20  2023-01-01  03:00  2023-01-01 03:00      0.0       0.0     22.0   \n",
       "4        20  2023-01-01  04:00  2023-01-01 04:00      0.0       0.0     11.0   \n",
       "\n",
       "   FUSS_OUT      Ost     Nord  ...  p [hPa]    Year  AnzBestWir  \\\n",
       "0      31.0  2682689  1247735  ...   971.62  2023.0    447082.0   \n",
       "1      94.0  2682689  1247735  ...   971.86  2023.0    447082.0   \n",
       "2      27.0  2682689  1247735  ...   971.76  2023.0    447082.0   \n",
       "3      27.0  2682689  1247735  ...   972.01  2023.0    447082.0   \n",
       "4      33.0  2682689  1247735  ...   972.10  2023.0    447082.0   \n",
       "\n",
       "     bezeichnung   fk_zaehler  id1  richtung_in  richtung_out  \\\n",
       "0  Militärbrücke  U15G3063864   20   Löwenplatz   Langstrasse   \n",
       "1  Militärbrücke  U15G3063864   20   Löwenplatz   Langstrasse   \n",
       "2  Militärbrücke  U15G3063864   20   Löwenplatz   Langstrasse   \n",
       "3  Militärbrücke  U15G3063864   20   Löwenplatz   Langstrasse   \n",
       "4  Militärbrücke  U15G3063864   20   Löwenplatz   Langstrasse   \n",
       "\n",
       "   korrekturfaktor                   geometry  \n",
       "0             0.58  POINT (2682689 1247734.9)  \n",
       "1             0.58  POINT (2682689 1247734.9)  \n",
       "2             0.58  POINT (2682689 1247734.9)  \n",
       "3             0.58  POINT (2682689 1247734.9)  \n",
       "4             0.58  POINT (2682689 1247734.9)  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the prepared data set\n",
    "dat = pd.read_csv('../../results/df_agg_hourly.csv')\n",
    "\n",
    "# Check the data\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Standort', 'Date', 'Time', 'Datetime', 'VELO_IN', 'VELO_OUT',\n",
       "       'FUSS_IN', 'FUSS_OUT', 'Ost', 'Nord', 'Hr [%Hr]', 'RainDur [min]',\n",
       "       'StrGlo [W/m2]', 'T [°C]', 'WD [°]', 'WVs [m/s]', 'WVv [m/s]',\n",
       "       'p [hPa]', 'Year', 'AnzBestWir', 'bezeichnung', 'fk_zaehler', 'id1',\n",
       "       'richtung_in', 'richtung_out', 'korrekturfaktor', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the different variables\n",
    "dat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Hours and Months from the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/m_/kjymw9sd0yn2wk8yjj853n_c0000gn/T/ipykernel_46549/4093744424.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  dat['hour'] = pd.to_datetime(dat['Time']).dt.hour\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    2\n",
       "3    3\n",
       "4    4\n",
       "Name: hour, dtype: int32"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the hours from the time column\n",
    "dat['hour'] = pd.to_datetime(dat['Time']).dt.hour\n",
    "\n",
    "# Check the data\n",
    "dat['hour'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: month, dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the month from the Date column\n",
    "dat['month'] = pd.to_datetime(dat['Date']).dt.month\n",
    "\n",
    "# Check the data\n",
    "dat['month'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Counts for the Bike and Foot Traffic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add up the bycicle and pedestrian counts\n",
    "dat['bike_tot'] = dat['VELO_IN'] + dat['VELO_OUT']\n",
    "dat['ped_tot'] = dat['FUSS_IN'] + dat['FUSS_OUT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NA handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standort              0\n",
      "Date                  0\n",
      "Time                  0\n",
      "Datetime              0\n",
      "VELO_IN               0\n",
      "VELO_OUT              0\n",
      "FUSS_IN               0\n",
      "FUSS_OUT              0\n",
      "Ost                   0\n",
      "Nord                  0\n",
      "Hr [%Hr]            173\n",
      "RainDur [min]       137\n",
      "StrGlo [W/m2]       137\n",
      "T [°C]              173\n",
      "WD [°]               90\n",
      "WVs [m/s]           222\n",
      "WVv [m/s]            90\n",
      "p [hPa]             113\n",
      "Year                 27\n",
      "AnzBestWir           27\n",
      "bezeichnung           0\n",
      "fk_zaehler            0\n",
      "id1                   0\n",
      "richtung_in           0\n",
      "richtung_out       3792\n",
      "korrekturfaktor       0\n",
      "geometry              0\n",
      "hour                  0\n",
      "month                 0\n",
      "bike_tot              0\n",
      "ped_tot               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Are there NAs in the data?\n",
    "print(dat.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before dropping the NAs, let's select the columns which we will actually be using for the RF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standort             int64\n",
       "Date                object\n",
       "Time                object\n",
       "Datetime            object\n",
       "VELO_IN            float64\n",
       "VELO_OUT           float64\n",
       "FUSS_IN            float64\n",
       "FUSS_OUT           float64\n",
       "Ost                  int64\n",
       "Nord                 int64\n",
       "Hr [%Hr]           float64\n",
       "RainDur [min]      float64\n",
       "StrGlo [W/m2]      float64\n",
       "T [°C]             float64\n",
       "WD [°]             float64\n",
       "WVs [m/s]          float64\n",
       "WVv [m/s]          float64\n",
       "p [hPa]            float64\n",
       "Year               float64\n",
       "AnzBestWir         float64\n",
       "bezeichnung         object\n",
       "fk_zaehler          object\n",
       "id1                  int64\n",
       "richtung_in         object\n",
       "richtung_out        object\n",
       "korrekturfaktor    float64\n",
       "geometry            object\n",
       "hour                 int32\n",
       "month                int32\n",
       "bike_tot           float64\n",
       "ped_tot            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's have a look at the data types\n",
    "dat.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standort             int64\n",
       "VELO_IN            float64\n",
       "VELO_OUT           float64\n",
       "FUSS_IN            float64\n",
       "FUSS_OUT           float64\n",
       "Ost                  int64\n",
       "Nord                 int64\n",
       "Hr [%Hr]           float64\n",
       "RainDur [min]      float64\n",
       "StrGlo [W/m2]      float64\n",
       "T [°C]             float64\n",
       "WD [°]             float64\n",
       "WVs [m/s]          float64\n",
       "WVv [m/s]          float64\n",
       "p [hPa]            float64\n",
       "Year               float64\n",
       "AnzBestWir         float64\n",
       "id1                  int64\n",
       "korrekturfaktor    float64\n",
       "hour                 int32\n",
       "month                int32\n",
       "bike_tot           float64\n",
       "ped_tot            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "dd = dat.select_dtypes(include=numerics)\n",
    "\n",
    "# Let's have a look at the data types\n",
    "dd.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's exclude the columns that are not needed anymore\n",
    "dd = dd.drop(['VELO_IN', 'VELO_OUT', 'FUSS_IN', 'FUSS_OUT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Standort', 'Ost', 'Nord', 'Hr [%Hr]', 'RainDur [min]', 'StrGlo [W/m2]',\n",
       "       'T [°C]', 'WD [°]', 'WVs [m/s]', 'WVv [m/s]', 'p [hPa]', 'Year',\n",
       "       'AnzBestWir', 'id1', 'korrekturfaktor', 'hour', 'month', 'bike_tot',\n",
       "       'ped_tot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which columns are left?\n",
    "dd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select essential variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NAs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for Bike Traffic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we have to define the target variable and the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Standort             int64\n",
       "Ost                  int64\n",
       "Nord                 int64\n",
       "Hr [%Hr]           float64\n",
       "RainDur [min]      float64\n",
       "StrGlo [W/m2]      float64\n",
       "T [°C]             float64\n",
       "WD [°]             float64\n",
       "WVs [m/s]          float64\n",
       "WVv [m/s]          float64\n",
       "p [hPa]            float64\n",
       "Year               float64\n",
       "AnzBestWir         float64\n",
       "id1                  int64\n",
       "korrekturfaktor    float64\n",
       "hour                 int32\n",
       "month                int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target variable\n",
    "y = dat['bike_tot']\n",
    "\n",
    "# Define the features\n",
    "X = dat.drop(['ped_tot'], axis=1)\n",
    "\n",
    "# Check data types\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154772, 17) (66331, 17) (154772,) (66331,)\n"
     ]
    }
   ],
   "source": [
    "# Split into test and training data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Check the shapes of the data\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/ensemble/_forest.py:348\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[1;32m    349\u001b[0m     X, y, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mDTYPE\n\u001b[1;32m    350\u001b[0m )\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    352\u001b[0m     sample_weight \u001b[38;5;241m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[1;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1145\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[1;32m   1148\u001b[0m     X,\n\u001b[1;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[1;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[1;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[1;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[1;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[1;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[1;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[1;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[1;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[1;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:959\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    954\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    955\u001b[0m             \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    956\u001b[0m         )\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 959\u001b[0m         _assert_all_finite(\n\u001b[1;32m    960\u001b[0m             array,\n\u001b[1;32m    961\u001b[0m             input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    962\u001b[0m             estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    963\u001b[0m             allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    964\u001b[0m         )\n\u001b[1;32m    966\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    967\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:124\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m _assert_all_finite_element_wise(\n\u001b[1;32m    125\u001b[0m     X,\n\u001b[1;32m    126\u001b[0m     xp\u001b[38;5;241m=\u001b[39mxp,\n\u001b[1;32m    127\u001b[0m     allow_nan\u001b[38;5;241m=\u001b[39mallow_nan,\n\u001b[1;32m    128\u001b[0m     msg_dtype\u001b[38;5;241m=\u001b[39mmsg_dtype,\n\u001b[1;32m    129\u001b[0m     estimator_name\u001b[38;5;241m=\u001b[39mestimator_name,\n\u001b[1;32m    130\u001b[0m     input_name\u001b[38;5;241m=\u001b[39minput_name,\n\u001b[1;32m    131\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:173\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[0;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m     )\n\u001b[0;32m--> 173\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nRandomForestRegressor does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
