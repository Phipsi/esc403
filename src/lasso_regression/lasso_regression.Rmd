---
title: "Lasso Regression"
author: "Philipp Wyss"
date: "2024-04-23"
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: true
    smooth_scroll: false
    df_print: paged
    code_folding: hide

    highlight: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      fig.width=9, fig.height=5,
                      fig.path='../../results/fig_lasso_regression/',
                      cache = TRUE,
                      cache.path = './cache/')

# Load libraries
library(tidyverse)
library(lubridate)
library(glmnet)
library(zoo)
library(xts)
library(forecast)
```

# Load Data
Loading the hourly aggregated dataset.
```{r read data}
dat <- read.csv('../../results/df_agg_hourly.csv')
# dat <- read.csv('results/df_agg_hourly.csv')
```

Next we decide which location to use. We will use the location with the most data available.
```{r select location}
# Select the location
select_standort <- 1037

# Deciding which location to use
dat %>% 
  filter(Standort == select_standort) %>%
  select(Standort, bezeichnung) %>%
  unique()

# Check the time range of the data
range(dat[dat$Standort == select_standort, ]$Datetime)
```

# Data Preperation

**Attention**: Most data preperation is taking place in `üìÅ ./src/data_preparation.ipynb`.

What we are doing here:
1. Cast Date and Time Variables into proper datatypes
2. Calculate the total traffic (`VELO_TOT` = `VELO_IN` + `VELO_OUT`)
3. Filter for `Standort == 1037` (Hardbr√ºcke S√ºd (Seite HB))
4. Select only variables that are of interest

```{r data preperation}
prep <- dat %>% mutate(
  # Cast Date & Datetime to proper Timestamps using libridate
  Date = lubridate::ymd(Date),
  Datetime = lubridate::ymd_hm(Datetime),
  Weekday = weekdays(Date),
  # Convert Time to integer
  Time = as.integer(substr(Time, 1, 2)),
  # Calculate total traffic
  VELO_TOT = VELO_IN + VELO_OUT,
  FUSS_TOT = FUSS_IN + FUSS_OUT
) %>%
  # Filter for Standort 20 (Milit√§rbr√ºcke / Langstrasse)
  filter(Standort == 1037) %>%
  # Select only variables that are of interest
  select(Standort,
         Date,
         Time,
         Datetime,
         Weekday,
         # Actual measurements
         VELO_TOT,
         FUSS_TOT,
         # Weather variables
         Hr...Hr.,
         RainDur..min.,
         StrGlo..W.m2.,
         T...C.,
         WD....,
         WVs..m.s.,
         WVv..m.s.,
         p..hPa.,
         # Additional lacations descriptive variables
         bezeichnung,
         richtung_in,
         richtung_out,
         korrekturfaktor) %>%
  # Transform Weekday to ordered factor starting with Monday
  mutate(Weekday = factor(Weekday, 
                          levels = c("Montag", "Dienstag", 
                                     "Mittwoch", "Donnerstag", 
                                     "Freitag", "Samstag", "Sonntag"))) %>%
  # Create new month variable
  mutate(Month = lubridate::month(Date, label = TRUE))

# Check the first few rows
prep %>% 
  select(Standort, bezeichnung, Weekday, Date, Time, VELO_TOT, FUSS_TOT) %>%
  head()
```


# EDA
Visualizing the data to get a better understanding of the data.

**Attention**: All plots and images generated here will be saved in `üìÅ ./results/fig_lasso_regression/`.

## Timeseries

```{r rolling mean daily traffic}
# Calculate the rolling mean
prep %>%
  filter(FUSS_TOT == 0 & VELO_TOT > 0) %>%
  group_by(Date) %>%
  summarise(Traffic = sum(VELO_TOT)) %>%
  # Calculate the rolling mean
  mutate(rolling_mean = zoo::rollmean(Traffic, k = 7, fill = NA)) %>%
  # Calculate the rolling std
  mutate(rolling_std = zoo::rollapply(Traffic, width = 7, FUN = sd, fill = NA)) %>%
  # Plot the timeseries
  ggplot(aes(x = Date, y = Traffic)) +
  geom_point() +
  geom_line(aes(x = Date, y = rolling_std, colour = "rolling std")) +
  #geom_ribbon(aes(ymin = rolling_mean - rolling_std, ymax = rolling_mean + rolling_std), fill = "darkgreen", alpha = 0.2) +
  geom_line(aes(x = Date, y = rolling_mean, colour = "rolling mean")) +
  scale_color_manual(name = "", values = c("rolling std" = "darkgreen", "rolling mean" = "red")) +
  theme_classic() +
  theme(legend.position = "bottom") + 
  ylab("Velo Traffic") +
  ggtitle(paste("Bike traffic at", prep$bezeichnung[1], "by day from Jan - Dec 2023"), subtitle = "Rolling mean and standard deviation for all observations")

```

```{r custom weekday colours}
weekday_colours <- c(
      "Montag" = "#DFE2E8",
      "Dienstag" = "#AEB7C6",
      "Mittwoch" = "#9EA8BA",
      "Donnerstag" = "#8D99AE",
      "Freitag" = "#808EA5",
      "Samstag" = "#F47382",
      "Sonntag" = "#D90429")
```


```{r plot timeseries daily traffic}
prep %>%
  filter(FUSS_TOT == 0 & VELO_TOT > 0) %>%
  # Group by Date
  group_by(Date, Weekday) %>%
  # Summarize the total traffic
  summarise(Traffic = sum(VELO_TOT)) %>%
  # Plot the timeseries
  ggplot(aes(x = Date, y = Traffic, col = Weekday)) + 
  geom_point() +
  geom_line() +
  theme_classic() +
  ylab("Velo Traffic") +
  ggtitle(paste("Bike traffic at", prep$bezeichnung[1], "by day from Jan - Dec 2023")) +
  theme(legend.position = "bottom") + 
  # Manualy set color scale
  scale_colour_manual(
    values = weekday_colours
  )
```


## Boxplot
```{r boxplot monthly traffic}
prep %>%
  # Select only the variables we need
  select(Month, Weekday, VELO_TOT) %>%
  # Filter only Jan & Feb
  filter(Month %in% c("Apr", "Jul", "Nov")) %>%
  # Plot the boxplot
  ggplot(aes(x = Month, y = VELO_TOT, col = Weekday)) +
  geom_boxplot() +
  theme_classic() +
  ylab("Velo Traffic") +
  ggtitle(paste("Monthly bike traffic at", prep$bezeichnung[1], "by month from Jan - Dec 2023")) +
    theme(legend.position = "bottom") + 
    # Manualy set color scale
  scale_colour_manual(
    values = weekday_colours
  )
```


## Correlation Matrix
Relative humidity and temperature are highly correlated. This is expected as the relative humidity is a function of the temperature. We will remove the relative humidity from the model.
```{r correlation matrix}
# Calculate the correlation matrix
cor_matrix <- prep %>%
  select(VELO_TOT, Hr...Hr., RainDur..min., StrGlo..W.m2., T...C., WD...., WVs..m.s., WVv..m.s., p..hPa.) %>%
  cor()

print(round(cor_matrix[1,],4))

# Plot the correlation matrix
corrplot::corrplot(cor_matrix, method = "color", type = "upper", order = "hclust", tl.col = "black", tl.srt = 45)

```


## Plot RainDur

```{r plot raindur}
# Plot RainDur and StrGlo as a function of Datetime
# First transfrom the data to long format
# Then plot the values as bars and add facet_wrap by the variable
prep %>%
  head(200) %>%
  pivot_longer(cols = c(RainDur..min., StrGlo..W.m2.), 
              names_to = "Variable", 
              values_to = "Value") %>%
  ggplot(aes(x = Datetime, y = Value)) +
  geom_bar(stat = "identity") +
  facet_wrap(vars(Variable), ncol = 1) +
  theme_classic() +
  ylab("Value") +
  ggtitle(paste("Rain duration and global radiation at", prep$bezeichnung[1], "by day in January")) +
  theme(legend.position = "bottom")
```

# Time Series Analysis
First we create a time series object

```{r create time series object}
# Create a time series object using xts
Velo <- xts::xts(x = prep$VELO_TOT, 
               order.by = prep$Datetime, 
               frequency = 8758)

# Plot the time series
plot(Velo)
```

### ACF
The ACF statistic measures the correlation between xt and xt+k where k is the number of lead periods into the future. It measures the correlation between any two points based on a given interval. It is not strictly equivalent to the Pearson product moment correlation. In R, ACF is calculated and visualized with the function ‚Äúacf‚Äù.

```{r autocorrelation function}
acf(Velo)
```

```{r partial autocorrelation function}

```

