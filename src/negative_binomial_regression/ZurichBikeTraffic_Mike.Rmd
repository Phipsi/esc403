---
title: "Zurich Bike Traffic"
author: "Mike Krähenbühl"
date: "2024-04-22"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Exploratory Data Analysis



```{r}

# article qualitatively describing the counting concept
# https://www.stadt-zuerich.ch/ted/de/index/taz/verkehr/webartikel/webartikel_velozaehlungen.html

# raw dataset 
#https://data.stadt-zuerich.ch/dataset/ted_taz_verkehrszaehlungen_werte_fussgaenger_velo

data <- read.csv('../../results/df_agg_hourly.csv', header = TRUE)

head(data)
str(data)

data$velo_traffic <- data$VELO_IN + data$VELO_OUT



# Create month column
data$Month <- format(as.Date(data$Date), "%m")


# Create day column
data$Day <- format(as.Date(data$Date), "%d")

# Create a weekday column
data$Weekday <- as.factor(weekdays(as.Date(data$Date)))


# Quaibrücke Süd (Seeseite)
# POINT (2683407.5 1246794.6)


sort(unique(data$Nord))
sort(unique(data$Ost))

unique(data$bezeichnung)
table(data$bezeichnung)

# select a station with only velo traffic
one_station <- data[data$bezeichnung == "Langstrasse (Unterführung Nord)",]


library(dplyr)

# for some Datetimes we have two rows, one for bike and one for foot.
# We only select the Standort 2989 as this one is for velo and the other for foot.
one_station_velo <- one_station[one_station$Standort==2989,]


#velo_traff <- one_station[,c("Datetime", "velo_traffic")]

```



Now we have a clean dataset for the station langstrasse to investigate the velo traffic. The amount of bikes in the two direction is very different because there are multiple measurement points at the langstrasse unterführung. This one is "Unterführung Nord".

```{r}


colSums(one_station_velo[,c("VELO_IN", "VELO_OUT")])


```



```{r}
library(ggplot2)
library(ggcorrplot)
library(tidyr)


# Calculate correlation matrix

correlation_matrix <- cor(na.omit(subset(one_station_velo, select = c("velo_traffic", "Hr...Hr.", "RainDur..min.", "StrGlo..W.m2.", "T...C." , "WD...." , "WVs..m.s.","WVv..m.s.","p..hPa."))))
rownames(correlation_matrix) <- colnames(correlation_matrix)

dim(correlation_matrix)

library(heatmaply)
heatmap(correlation_matrix,
        Rowv = NA, Colv = NA,
        col = heat.colors(256),
        scale = "none",
        margins = c(5, 10),
        main = "Correlation Heatmap")


barplot(correlation_matrix[1,], las=2, 
        main= " Correlation with velo_traffic",
        ylab="Correlation")


```

The relative humidity seems to have the highest (negative) correlation with velo_traffic. Surprisingly, the rain duration is only weakly correlated. The global radiation and the temperature are positively correlated with velo_traffic.




## Regression model


First we analyze the outcome variable velo_traffic. Since it is count data, a poisson regression might be appropriate. Let's check the assumptions:


* Response follows poisson distribution: Yes, count data per time unit (hour)
* Independence: Yes, the velo_traffic depends on time and other variables but not necessarily on previous velo_traffic.
*
* Mean = Variance: this assumption is clearly not met since variance i smuch larger than mean.

```{r}


# looks like poisson (makes sense because counts per time unit)
hist(one_station_velo$velo_traffic)
plot(seq(1,length(one_station_velo$velo_traffic)), log(1/one_station_velo$velo_traffic))

# var > mean --> this means we have overdispersion
mean(one_station_velo$velo_traffic)
var(one_station_velo$velo_traffic)


```

Since we have over-dispersion (variance > mean) a Poisson regression cannot properly model the data because it has only one parameter $\lambda$. Therefore the negative binomial distribution, which is a generalization of the poisson regression that has one additional parameter to model the over-dispersion.


## Negative binomial regression



```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
model1<-glm.nb(velo_traffic ~ Weekday + RainDur..min., data=one_station_velo)


summary(model1)

prediction_errors <- (predict(model1, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))


```

```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
glm_nb_2<-glm.nb(velo_traffic ~ Weekday + StrGlo..W.m2. + RainDur..min., data=one_station_velo)


summary(glm_nb_2)

prediction_errors <- (predict(glm_nb_2, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))


```


```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
glm_nb_3<-glm.nb(velo_traffic ~ as.factor(Time) + Weekday + StrGlo..W.m2. + RainDur..min., data=one_station_velo)


summary(glm_nb_3)

prediction_errors <- (predict(glm_nb_3, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))


```





```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
glm_nb_4 <-glm.nb(velo_traffic ~ Time + Weekday + Month+ StrGlo..W.m2. +WVv..m.s.  + T...C. + RainDur..min., data=one_station_velo)


summary(glm_nb_4)

prediction_errors <- (predict(glm_nb_4, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))


```


```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
glm_nb_5 <-glm.nb(velo_traffic ~ Time + Weekday + Month+ StrGlo..W.m2. +WVv..m.s.  + T...C. + RainDur..min.+ p..hPa. + Hr...Hr., data=one_station_velo)


summary(glm_nb_5)

prediction_errors <- (predict(glm_nb_5, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))

str(one_station_2022)
```

## Poisson regression




```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.

set.seed(123)
model_pois<-glm(velo_traffic ~ Weekday + RainDur..min., family=poisson(link="log"), data=one_station_velo)

summary(model_pois)


prediction_errors <- (predict(model_pois, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))
```


```{r}

model2 <-glm(velo_traffic ~ Time + RainDur..min.  + T...C., family=poisson(link="log"), data=one_station_velo)

summary(model2)

prediction_errors <- (predict(model2, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))
```


Linear model just as a comparison

```{r}


lm <-lm(velo_traffic ~ as.factor(Time) + Weekday + Month+ StrGlo..W.m2. + T...C. + RainDur..min., data=one_station_velo)

summary(lm)


prediction_errors <- (predict(lm, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))
```


```{r}

# make a dataframe with new data
newdata = data.frame(Time = "10:00" , RainDur..min.= 10  , T...C. = 20.62)

# use 'predict()' to run model on new data
predict(model2, newdata = newdata, type = "response")
```






## Model validation (2022 data)


```{r}

# load 2022 data


data2022 <- read.csv('../../results/df_agg_hourly_2022.csv', header = TRUE)

head(data2022)
str(data2022)

data2022$velo_traffic <- data2022$VELO_IN + data2022$VELO_OUT



# Create month column
data2022$Month <- format(as.Date(data2022$Date), "%m")


# Create day column
data2022$Day <- format(as.Date(data2022$Date), "%d")

# Create a weekday column
data2022$Weekday <- as.factor(weekdays(as.Date(data2022$Date)))


# Quaibrücke Süd (Seeseite)
# POINT (2683407.5 1246794.6)


sort(unique(data2022$Nord))
sort(unique(data2022$Ost))

unique(data2022$bezeichnung)
table(data2022$bezeichnung)

# select a station with only velo traffic
one_station_2022 <- data2022[data2022$bezeichnung == "Langstrasse (Unterführung Nord)",]


library(dplyr)

# for some Datetimes we have two rows, one for bike and one for foot.
# We only select the Standort 2989 as this one is for velo and the other for foot.
one_station_velo_2022 <- one_station_2022[one_station_2022$Standort==2989,]


mean(one_station_velo_2022$velo_traffic)

max(one_station_velo_2022$velo_traffic)

```

Compare the model accuracies on the 2022 data. for the accuracy we take the prediction (backtransformed), subtract the true value and square it. The square root of the mean squared error (MSE) is then the accuracy score (average error).


```{r}

get_pred_error <- function(model){
  prediction_errors <- (predict(model, one_station_velo_2022, type="response") - one_station_velo_2022$velo_traffic)^2

# sum(length(which(is.na(prediction_errors)) ))
 
 mean_pred_error <- sqrt(mean(na.omit(prediction_errors)))
 return(mean_pred_error)
  
}



# negative binomial

get_pred_error(model1)

get_pred_error(glm_nb_2)

get_pred_error(glm_nb_3)

get_pred_error(glm_nb_4)


# poisson
get_pred_error(model_pois)

get_pred_error(model2)

# linear
get_pred_error(lm)


```


As in the training set, the the model glm_nb_4 perfomrmed best. Following we discuss this model:

```{r}
summary(glm_nb_4)

```



The model is a generalized linear model, or more specifically a negative-binomial regression. It was fitted using the factor variables Time, Weekday and Month and the numerical variables Global radiation (W/m2), Temperature (celsius) and the rain duration (minutes). Most parameters in the model are significant at a 5% significance level. The only exceptions are the weekday wednesday and the month august.

```{r}


coefficients(glm_nb_4)["T...C."]


exp(coefficients(glm_nb_4)["T...C."])

```


The coefficient for the variable temperature is 0.0284 . This means that for each one-unit increase in temperature, the expected log count of bike traffic in one hour increases by 0.0284 (if all other variables remain unchanged).


```{r}

comparison <- data.frame(true_value = one_station_velo_2022$velo_traffic, prediction = predict(glm_nb_4, one_station_velo_2022, type="response"))



# For visualization prediction vs true value of first week July 2022

# Subset data for the month of July
july_data <- one_station_velo_2022[one_station_velo_2022$Month== "07", ]

# Further subset to show only the first week of July
first_week_july <- july_data[july_data$Datetime <= as.POSIXct("2022-07-07"), ]

# Create comparison dataframe for the first week of July
comparison_first_week <- data.frame(true_value = first_week_july$velo_traffic,
                                    prediction = predict(glm_nb_4, first_week_july, type="response"))

# Extract unique dates (start of each day)
unique_dates <- c("2022-07-01 00:00", "2022-07-02 00:00", "2022-07-03 00:00",
                  "2022-07-04 00:00", "2022-07-05 00:00", "2022-07-06 00:00",
                  "2022-07-07 00:00")

# Plot
plot(1:nrow(first_week_july), comparison_first_week$true_value, type="l", xlab="Day of the Week", ylab="Count", ylim=c(0, max(comparison_first_week$true_value, comparison_first_week$prediction)), xaxt="n")
lines(1:nrow(first_week_july), comparison_first_week$prediction, col="red")

# Add legend
legend("topleft", legend=c("True Value", "Prediction"), col=c("black", "red"), lty=1)

# Add x-axis labels for weekdays
axis(1, at=which(first_week_july$Datetime %in% unique_dates), labels=format(as.Date(unique_dates), "%A"), las=1)




```

```{r}


comparison$difference <- comparison$true_value - 
  comparison$prediction

plot(comparison$difference, type="l")

```




## glm.nb train on 2022 test on 2023

Train on 2022

```{r}

# weather data
# Luftdruck (p), die Niederschlagsdauer (RainDur), die Globalstrahlung (StrGlo), die Temperatur (T), die relative Luftfeuchtigkeit (Hr), die Windrichtung, die Vektor und Skalar Windgeschwindigkeit.
library(MASS)
set.seed(123)
glm_nb_4 <-glm.nb(velo_traffic ~ Time + Weekday + Month+ StrGlo..W.m2. +WVv..m.s.  + T...C. + RainDur..min., data=one_station_velo_2022)


summary(glm_nb_4)

prediction_errors <- (predict(glm_nb_4, one_station_velo_2022, type="response") - one_station_velo_2022$velo_traffic)^2

 sum(length(which(is.na(prediction_errors)) ))
 
 sqrt(mean(na.omit(prediction_errors)))


```

Test on 2023

```{r}

get_pred_error_2023 <- function(model){
  prediction_errors <- (predict(model, one_station_velo, type="response") - one_station_velo$velo_traffic)^2

# sum(length(which(is.na(prediction_errors)) ))
 
 mean_pred_error <- sqrt(mean(na.omit(prediction_errors)))
 return(mean_pred_error)
  
}



# negative binomial

get_pred_error_2023(glm_nb_4)


```

```{r}

comparison <- data.frame(true_value = one_station_velo$velo_traffic, prediction = predict(glm_nb_4, one_station_velo, type="response"))



# For visualization prediction vs true value of first week July 2023

# Subset data for the month of July
july_data <- one_station_velo[one_station_velo$Month== "07", ]

# Further subset to show only the first week of July
first_week_july <- july_data[july_data$Datetime <= as.POSIXct("2023-07-07"), ]

# Create comparison dataframe for the first week of July
comparison_first_week <- data.frame(true_value = first_week_july$velo_traffic,
                                    prediction = predict(glm_nb_4, first_week_july, type="response"))

# Extract unique dates (start of each day)
unique_dates <- c("2023-07-01 00:00", "2023-07-02 00:00", "2023-07-03 00:00",
                  "2023-07-04 00:00", "2023-07-05 00:00", "2023-07-06 00:00",
                  "2023-07-07 00:00")

# Plot
plot(1:nrow(first_week_july), comparison_first_week$true_value, type="l", xlab="Day of the Week", ylab="Count", ylim=c(0, max(comparison_first_week$true_value, comparison_first_week$prediction)), xaxt="n")
lines(1:nrow(first_week_july), comparison_first_week$prediction, col="red")

# Add legend
legend("topleft", legend=c("True Value", "Prediction"), col=c("black", "red"), lty=1)

# Add x-axis labels for weekdays
axis(1, at=which(first_week_july$Datetime %in% unique_dates), labels=format(as.Date(unique_dates), "%A"), las=1)




```



```{r}


comparison <- data.frame(true_value = one_station_velo$velo_traffic, prediction = predict(glm_nb_4, one_station_velo, type="response"))



# For visualization prediction vs true value of first week July 2022

# Subset data for the month of July
july_data <- one_station_velo[one_station_velo$Month== "07", ]

# Further subset to show only the first week of July
first_week_july <- july_data[july_data$Datetime <= as.POSIXct("2023-07-07"), ]

# Create comparison dataframe for the first week of July
comparison_first_week <- data.frame(true_value = july_data$velo_traffic,
                                    prediction = predict(glm_nb_4, july_data, type="response"))

# Extract unique dates (start of each day)
#unique_dates <- c("2023-07-01 00:00", "2023-07-02 00:00", "2023-07-03 00:00",
#                  "2023-07-04 00:00", "2023-07-05 00:00", "2023-07-06 00:00",
#                  "2023-07-07 00:00")

# Plot
plot(1:nrow(comparison_first_week), comparison_first_week$true_value, type="l", xlab="Day of the Week", ylab="Count", ylim=c(0, max(comparison_first_week$true_value, comparison_first_week$prediction)), xaxt="n")
lines(1:nrow(comparison_first_week), comparison_first_week$prediction, col="red")

# Add legend
legend("topleft", legend=c("True Value", "Prediction"), col=c("black", "red"), lty=1)

# Add x-axis labels for weekdays
#axis(1, at=which(first_week_july$Datetime %in% unique_dates), labels=format(as.Date(unique_dates), "%A"), las=1)




```




Check if over or underestimated:


```{r}

comparison <- data.frame(true_value = one_station_velo$velo_traffic, prediction = predict(glm_nb_4, one_station_velo, type="response"))

comparison$diff <- comparison$prediction - comparison$true_value

plot(comparison$diff, type="l", main="Absolute difference")
plot(log(comparison$prediction)-log(comparison$true_value), type="l", main="Log difference")
plot(log(comparison$true_value/comparison$prediction), type="l", main="Relative difference")

sum(comparison$diff>0)
sum(comparison$diff<0)

```

























## Extreme value theory


We are interested on the maximum amount of bicycles that are likely to pass the measurement station in one hour within the next 10 years. We are not interested in predicting the mean but in the maximum. This might be an important 

```{r}

plot(one_station_velo$velo_traffic, xlab="Time (since 2023-01-01)", ylab="Bike traffic per hour")

plot(velo_traffic ~ Day, data=one_station_velo, xlab="Day", ylab="Bike traffic per hour")

boxplot(velo_traffic ~ Weekday, data=one_station_velo, xlab="Weekday", ylab="Bike traffic per hour")

plot(velo_traffic ~ Month, data=one_station_velo, xlab="Mont", ylab="Bike traffic per hour")


lines(1:12, c(by(one_station_velo$velo_traffic, one_station_velo$Month, median)), col=2, lwd=2)

# day and hour with the max traffic per hour in 2023
one_station_velo[which.max(one_station_velo$velo_traffic),]

```



### Pareto?

```{r}


```